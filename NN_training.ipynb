{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYjcvVW0aaJdMoJnBg2kXT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomJiX/ML_start/blob/main/NN_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMHxrDQded9P"
      },
      "source": [
        "Package import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouNvXiXBeaPh"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "import numpy as np\n",
        "import gc\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXjpvNV-epBl"
      },
      "source": [
        "Variable initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8L-rGnFeg5v"
      },
      "source": [
        "X = np.load(\"_\")\n",
        "y= np.load(\"_\")\n",
        "SAVE_MODEL_NAME=\"_\"\n",
        "\n",
        "if os.path.isfile(SAVE_MODEL_NAME+\".model\"):\n",
        "    SAVE_MODEL_NAME+=str(time.time())\n",
        "    \n",
        "X = X/255.0\n",
        "\n",
        "# dense_layers = [0, 1, 2]\n",
        "# layer_sizes = [32, 64, 128]\n",
        "# conv_layers = [1, 2, 3]\n",
        "\n",
        "dense_layers = [0]\n",
        "layer_sizes = [64]\n",
        "conv_layers = [3]\n",
        "\n",
        "EPOCHS=20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WImowBZbe-Op"
      },
      "source": [
        "Choose the type of NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS58B3esetCZ"
      },
      "source": [
        "def general_fit():\n",
        "    for dense_layer in dense_layers:\n",
        "        for layer_size in layer_sizes:\n",
        "            for conv_layer in conv_layers:\n",
        "                NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
        "                print(NAME)\n",
        "\n",
        "                model = Sequential()\n",
        "\n",
        "                model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
        "                model.add(Activation('relu'))\n",
        "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "                for l in range(conv_layer-1):\n",
        "                    model.add(Conv2D(layer_size, (3, 3)))\n",
        "                    model.add(Activation('relu'))\n",
        "                    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "                model.add(Flatten())\n",
        "\n",
        "                for _ in range(dense_layer):\n",
        "                    model.add(Dense(layer_size))\n",
        "                    model.add(Activation('relu'))\n",
        "\n",
        "                model.add(Dense(1))\n",
        "                model.add(Activation('sigmoid'))\n",
        "\n",
        "                tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "\n",
        "                model.compile(loss='binary_crossentropy',\n",
        "                            optimizer='adam',\n",
        "                            metrics=['accuracy'],\n",
        "                            )\n",
        "\n",
        "                model.fit(X, y,\n",
        "                        batch_size=32,\n",
        "                        epochs=EPOCHS,\n",
        "                        validation_split=0.3,\n",
        "                        callbacks=[tensorboard])\n",
        "                gc.collect()\n",
        "    model.save(SAVE_MODEL_NAME+\".model\")\n",
        "\n",
        "\n",
        "def particular_fit():\n",
        "    NAME = \"3conv32-64-128-1-dense\"+str(time.time())\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X.shape[1:]))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n",
        "\n",
        "\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    model.fit(X, y,\n",
        "                        batch_size=32,\n",
        "                        epochs=EPOCHS,\n",
        "                        validation_split=0.3,\n",
        "                        callbacks=[tensorboard])\n",
        "\n",
        "    \n",
        "\n",
        "    gc.collect()\n",
        "    model.save(SAVE_MODEL_NAME+\".model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpT_1tZXfB4E"
      },
      "source": [
        "Compute the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am2nSlKve1tY"
      },
      "source": [
        "#particular_fit()\n",
        "#general_fit()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}